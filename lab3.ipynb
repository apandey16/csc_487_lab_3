{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent(x, y, learning_rate, num_iterations):\n",
    "    samples = x.shape[0]\n",
    "    features = x.shape[1]\n",
    "\n",
    "    theta = np.zeros(features)\n",
    "    for i in range(num_iterations):\n",
    "        gradient = np.dot(x.T, np.dot(x, theta) - y) / samples\n",
    "        theta = theta - learning_rate * gradient\n",
    "    return theta\n",
    "\n",
    "def stochastic_gradient_descent(x, y, learning_rate, num_iterations):\n",
    "    samples = x.shape[0]\n",
    "    features = x.shape[1]\n",
    "\n",
    "    theta = np.zeros(features)\n",
    "    for _ in range(num_iterations):\n",
    "        optimize = np.random.permutation(samples)\n",
    "        for j in optimize:\n",
    "            gradient = np.dot(x[j].T, np.dot(x[j], theta) - y[j])\n",
    "            theta = theta - learning_rate * gradient\n",
    "    return theta\n",
    "\n",
    "def mini_batch_gradient_descent(x, y, learning_rate, num_iterations, batch_size):\n",
    "    samples = x.shape[0]\n",
    "    features = x.shape[1]\n",
    "\n",
    "    theta = np.zeros(features)\n",
    "    for i in range(num_iterations):\n",
    "        indices = np.random.permutation(samples)\n",
    "        x_shuffled = x[indices]\n",
    "        y_shuffled = y[indices]\n",
    "        for j in range(0, samples, batch_size):\n",
    "            x_batch = x_shuffled[j:j + batch_size]\n",
    "            y_batch = y_shuffled[j:j + batch_size]\n",
    "            gradient = np.dot(x_batch.T, np.dot(x_batch, theta) - y_batch) / batch_size\n",
    "            theta = theta - learning_rate * gradient\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fx/1qygjtws0tx6z85xxpz56r2c0000gn/T/ipykernel_73513/777274704.py:20: RuntimeWarning: invalid value encountered in subtract\n",
      "  theta = theta - learning_rate * gradient\n",
      "/var/folders/fx/1qygjtws0tx6z85xxpz56r2c0000gn/T/ipykernel_73513/777274704.py:36: RuntimeWarning: invalid value encountered in subtract\n",
      "  theta = theta - learning_rate * gradient\n",
      "/var/folders/fx/1qygjtws0tx6z85xxpz56r2c0000gn/T/ipykernel_73513/777274704.py:8: RuntimeWarning: invalid value encountered in subtract\n",
      "  theta = theta - learning_rate * gradient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.48998813e+000  2.49334199e+000]\n",
      " [ 1.48958918e+000  2.49376370e+000]\n",
      " [ 1.48958918e+000  2.49376370e+000]\n",
      " [-1.97061780e+288 -1.86425333e+288]\n",
      " [             nan              nan]]\n",
      "\n",
      "[[1.49002204 2.49532037]\n",
      " [1.48661379 2.49162792]\n",
      " [1.49460333 2.48871701]\n",
      " [       nan        nan]\n",
      " [       nan        nan]]\n",
      "\n",
      "[[1.48697153 2.49277746]\n",
      " [1.48990103 2.48779423]\n",
      " [1.47222948 2.49023523]\n",
      " [       nan        nan]\n",
      " [       nan        nan]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(100, 2) * 10  \n",
    "y = np.dot(x, np.array([1.5, 2.5])) + np.random.randn(100) * 0.5  \n",
    "\n",
    "# learning rate and number of iterations impace the theta values\n",
    "learning_rates = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "num_iterations = 1000\n",
    "\n",
    "batch_thetas = []\n",
    "stochastic_gradient_descent_thetas = []\n",
    "mini_batch_thetas = []\n",
    "\n",
    "for rate in learning_rates:\n",
    "    batch_theta = batch_gradient_descent(x, y, rate, num_iterations)\n",
    "    stochastic_theta = stochastic_gradient_descent(x, y, rate, num_iterations)\n",
    "    mini_batch_theta = mini_batch_gradient_descent(x, y, rate, num_iterations, 2)\n",
    "    stochastic_gradient_descent_thetas.append(stochastic_theta)\n",
    "    mini_batch_thetas.append(mini_batch_theta)\n",
    "    batch_thetas.append(batch_theta)\n",
    "\n",
    "batch_thetas = np.array(batch_thetas)\n",
    "stochastic_gradient_descent_thetas = np.array(stochastic_gradient_descent_thetas)\n",
    "mini_batch_thetas = np.array(mini_batch_thetas)\n",
    "\n",
    "print(batch_thetas)\n",
    "print()\n",
    "print(stochastic_gradient_descent_thetas)\n",
    "print()\n",
    "print(mini_batch_thetas)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
