{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent(x, y, learning_rate, num_iterations):\n",
    "    samples = x.shape[0]\n",
    "    features = x.shape[1]\n",
    "\n",
    "    theta = np.zeros(features)\n",
    "    for i in range(num_iterations):\n",
    "        gradient = np.dot(x.T, np.dot(x, theta) - y) / samples\n",
    "        theta = theta - learning_rate * gradient\n",
    "    return theta\n",
    "\n",
    "def stochastic_gradient_descent(x, y, learning_rate, num_iterations):\n",
    "    samples = x.shape[0]\n",
    "    features = x.shape[1]\n",
    "\n",
    "    theta = np.zeros(features)\n",
    "    for _ in range(num_iterations):\n",
    "        j = np.random.randint(samples)\n",
    "        gradient = np.dot(x[j].T, np.dot(x[j], theta) - y[j])\n",
    "        theta = theta - learning_rate * gradient\n",
    "    return theta\n",
    "\n",
    "def mini_batch_gradient_descent(x, y, learning_rate, num_iterations, batch_size):\n",
    "    samples = x.shape[0]\n",
    "    features = x.shape[1]\n",
    "\n",
    "    theta = np.zeros(features)\n",
    "    for i in range(num_iterations):\n",
    "        indices = np.random.choice(samples, batch_size, replace=False)\n",
    "        x_batch = x[indices]\n",
    "        y_batch = y[indices]\n",
    "        gradient = np.dot(x_batch.T, np.dot(x_batch, theta) - y_batch) / batch_size\n",
    "        theta = theta - learning_rate * gradient\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.50158068e+000  2.48951893e+000]\n",
      " [ 1.50151872e+000  2.48958592e+000]\n",
      " [ 1.50151872e+000  2.48958592e+000]\n",
      " [-2.82120345e+225 -2.60895109e+225]\n",
      " [             nan              nan]]\n",
      "\n",
      "[[ 1.49568917e+000  2.49118223e+000]\n",
      " [ 1.48835257e+000  2.48551294e+000]\n",
      " [ 1.57225424e+000  2.51504416e+000]\n",
      " [ 4.56161528e+170 -1.89420741e+169]\n",
      " [             nan              nan]]\n",
      "\n",
      "[[1.49325675e+000 2.48411469e+000]\n",
      " [1.51945687e+000 2.50542768e+000]\n",
      " [1.50398046e+000 2.50659858e+000]\n",
      " [3.95001608e+102 7.93223734e+101]\n",
      " [            nan             nan]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fx/1qygjtws0tx6z85xxpz56r2c0000gn/T/ipykernel_98708/1003059013.py:8: RuntimeWarning: invalid value encountered in subtract\n",
      "  theta = theta - learning_rate * gradient\n",
      "/var/folders/fx/1qygjtws0tx6z85xxpz56r2c0000gn/T/ipykernel_98708/1003059013.py:19: RuntimeWarning: invalid value encountered in subtract\n",
      "  theta = theta - learning_rate * gradient\n",
      "/var/folders/fx/1qygjtws0tx6z85xxpz56r2c0000gn/T/ipykernel_98708/1003059013.py:32: RuntimeWarning: invalid value encountered in subtract\n",
      "  theta = theta - learning_rate * gradient\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(100, 2) * 10  \n",
    "y = np.dot(x, np.array([1.5, 2.5])) + np.random.randn(100) * 0.5  \n",
    "\n",
    "# learning rate and number of iterations impace the theta values\n",
    "learning_rates = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "num_iterations = 1000\n",
    "\n",
    "batch_thetas = []\n",
    "stochastic_gradient_descent_thetas = []\n",
    "mini_batch_thetas = []\n",
    "\n",
    "for rate in learning_rates:\n",
    "    batch_theta = batch_gradient_descent(x, y, rate, num_iterations)\n",
    "    stochastic_theta = stochastic_gradient_descent(x, y, rate, num_iterations)\n",
    "    mini_batch_theta = mini_batch_gradient_descent(x, y, rate, num_iterations, 2)\n",
    "    stochastic_gradient_descent_thetas.append(stochastic_theta)\n",
    "    mini_batch_thetas.append(mini_batch_theta)\n",
    "    batch_thetas.append(batch_theta)\n",
    "\n",
    "batch_thetas = np.array(batch_thetas)\n",
    "stochastic_gradient_descent_thetas = np.array(stochastic_gradient_descent_thetas)\n",
    "mini_batch_thetas = np.array(mini_batch_thetas)\n",
    "\n",
    "print(batch_thetas)\n",
    "print()\n",
    "print(stochastic_gradient_descent_thetas)\n",
    "print()\n",
    "print(mini_batch_thetas)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
